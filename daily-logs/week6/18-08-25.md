### Date & Topic

- **Date:** 18th August, 2025 
- **Main Focus:** Implemented Algorithm 3: Trust-Aware Validator Selection with Explainability for the paper *AI-Driven Validator Selection in PoS Blockchain Networks*

---

### 1. Search

- **What did you look for?**  
  - Methods of integrating trust scoring into validator ranking systems.
  - Academic examples of explainability (XAI) applied in blockchain or multi-agent systems.


- **Where did you search?**  
  - Reviewd few academic papers for getting ideas on writing pseudocode
  - Revisited git repos
  - Took help from the chatgpt and perplexity
  

- **Useful sources found:** 
    - IEEE articles on trust metrics in distributed consensus
    

---

### 2. Investigate

- **What did you dig into?**  
  - Designed pseudocode for ranking validators based on trust and performance scores.
  - Added selection logic for choosing top-k validators for committee participation.
  - Incorporated an explainability step that logs post-hoc explanations alongside scores.
  - Structured the algorithm into three clear modules: ranking, selection, explanation.
  

- **Any patterns or surprises?**  
  - None
  
  

---

### 3. Reflect

- **What did you learn?**  
  - Logging explanations alongside decisions builds an auditable trail that benefits both research and practical deployment.
- **Whatâ€™s next?**  
  - Plan to move on to Algorithm 4: Malicious Detection, Penalization, and Audit Trail.
  
  

---

### 4. Actions

- **Immediate actions:**  
  - Begin drafting pseudocode for Algorithm 4 tomorrow.
  - Review Algorithm 3 for alignment with the trust module and XAI framework.