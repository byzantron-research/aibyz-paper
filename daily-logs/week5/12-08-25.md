### Date & Topic

- **Date:** 12th August, 2025 
- **Main Focus:** Implemented chain-specific data collectors for Ethereum 2.0, Cosmos, and Polkadot within the paper *AI-Driven Validator Selection in PoS Blockchain Networks*

---

### 1. Search

- **What did you look for?**  
  - Best practices for structuring blockchain data ingestion pipelines across multiple protocols.



- **Where did you search?**  
  - Ethereum Beacon API documentation
  - Cosmos SDK API reference and public API endpoints
  - GitHub repositories implementing multi-chain data pipelines
  

- **Useful sources found:** 
    - https://github.com/SPaDeS-Lab/mrl-pos-plus
    - https://ethereum.github.io/beacon-APIs/
    - https://youtu.be/rEdJyoPLSME?si=w61dqHJXIv9U0bIb
   

---

### 2. Investigate

- **What did you dig into?**  
  - Implemented Eth2Collector, CosmosCollector, and PolkadotCollector to fetch network-specific data (blocks, validator info, attestations, penalties/slashing events) using respective APIs/libraries, following the raw data partitioning scheme with provenance metadata. However, testing the code is yet to be done.
  - Also, integrateds all collectors with CLI

- **Any patterns or surprises?**  
  - None
  
  

---

### 3. Reflect

- **What did you learn?**  
  - Having the same output file and way of tracking where data came from across all collectors makes it easier to do curation and feature building later on.

- **What’s next?**  
  - Will begin implementing curator modules to normalize raw → curated datasets.
  
  

---

### 4. Actions

- **Immediate actions:**  
  - Will start testing each collector end-to-end with small ranges to validate output structure and metadata logging