### Date & Topic

- **Date:** 15th July, 2025 
- **Main Focus:** Identifying limitations in existing AI-enhanced BFT systems and refining the research direction for “AI-Driven Validator Selection for Byzantine-Resilient Distributed Systems”

---

### 1. Search

- **What did you look for?**  
  - Common pitfalls in current AI-enhanced BFT systems.
  - Gaps in validator selection mechanisms within distributed consensus.
  - Relevant literature supporting the novelty of ML-based, explainable, and self-healing validator selection.
  - How existing systems handle trust, transparency, fault tolerance, and decentralization.

- **Where did you search?**  
  - arXiv, ScienceDirect, Ethereum and Tendermint documentation, Google Scholar, Nature, and peer-reviewed surveys.

- **Useful sources found:**  
  - Wu et al. (2024), *BFTBrain: Adaptive BFT Consensus with RL* → [arXiv:2504.14668](https://doi.org/10.48550/arXiv.2504.14668)  
  - Rizal & Kim (2023), *Survey on ML Applications in Blockchain Consensus* → [ScienceDirect]( https://www.sciencedirect.com/science/article/pii/S2096720925000296?via%3Dihub)
  - Venkatesan & Rahayu (2023), *Hybrid Consensus with ML* → [ScientificReport](https://www.nature.com/articles/s41598-024-51578-7)  
  - deVadoss & Artzt (2024), *A BFT Architecture for AI Safety*  
  - Tendermint / Cosmos SDK documentation

---

### 2. Investigate

- **What did you dig into?**  
  - Identified concrete shortcomings in current systems:
    - Validator selection is static or stake-only.
    - RL is only used for protocol switching, not node trust management.
    - No real-time anomaly detection or auto-removal of faulty validators.
    - Systems lack explainable AI components.
  - Designed a novel architecture combining LightGBM, RL, SHAP/LIME, anomaly detection, and self-healing validator reassignment.
  - Drafted a list of novel contributions and how they directly solve existing real-world gaps.

- **Any patterns or surprises?**  
  - Most research papers assume protocol performance = system robustness, ignoring trust dynamics at the validator level.
  - No major system currently integrates explainability (SHAP, LIME) for validator trust decisions.
  - Centralization due to stake bias is widely acknowledged, but rarely addressed with ML.

---

### 3. Reflect

- **What did you learn?**  
  - The field lacks a practical, explainable, and adaptive validator selection strategy.
  - Our approach directly responds to gaps in current BFT+AI systems, offering a narrow and impactful scope.
  - Validator behavior is underutilized as a metric — most focus is still on static identity or stake.

- **What’s next?**  
  - Begin designing the ML model inputs (feature set for validator scoring).
  - Create initial diagrams for architecture and self-healing flow.
  - Simulate a testnet scenario with at least 5 validators and fault injection.
  - Formalize novelty + contribution for the proposal.

---

### 4. Actions

- **Immediate actions:**  
  - Write the formal “Problem Statement” and “Novel Contributions” section using today’s findings.
  - Create a literature comparison matrix (Existing Systems vs. Your Approach).
  - Build a minimal experimental design proposal using Docker, Prometheus, and Tendermint.
  - Review SHAP/LIME examples for integration into ML-based validator trust scoring.
  - Identify open-source BFT implementations to fork for simulation (e.g., Tendermint Core, Bedrock).
